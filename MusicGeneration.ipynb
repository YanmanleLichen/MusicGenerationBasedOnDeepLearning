{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的音乐生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入必要库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" 从目录中的midi文件中获取所有音符和和弦 \"\"\"\n",
    "    notes = []\n",
    "    # 读取midi文件夹所有.mid文件\n",
    "    for file in glob.glob(\"midi/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        print(\"Parsing %s\" % file)\n",
    "        notes_to_parse = None\n",
    "        # 基于不同乐器的分组\n",
    "        try:\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        # 区分单个音符和和弦\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    # 将获取到的音符和和弦保存到文件中\n",
    "    with open('notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_prepare_sequences(notes):\n",
    "    \"\"\" 准备训练神经网络所需的序列 \"\"\"\n",
    "    sequence_length = 100\n",
    "    # 获取所有音高名称及数量\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "    # 通过字典来将音高映射为整数\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    # 创建输入序列和相应的输出序列\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "    n_patterns = len(network_input)\n",
    "    # 将输入调整为与LSTM层兼容的格式\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # 将输入标准化\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, notes, flag):\n",
    "    \"\"\" 创建用于训练和生成音乐的神经网络结构 \"\"\"\n",
    "    n_vocab = len(set(notes))\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        256,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(128, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    plot_model(model,to_file='model.png',show_shapes=True)\n",
    "    # train_flag为False时为生成模式\n",
    "    if (flag == False):\n",
    "        # 从模型文件将权重加载到每个节点\n",
    "        model.load_weights('model/0-2.0434.hdf5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" 训练神经网络 \"\"\"\n",
    "    # 每训练一轮保存一次模型，训练200轮\n",
    "    filepath = \"model/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        period=1\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "    history = model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" 开始训练模型 \"\"\"\n",
    "    # 获取所有音符和和弦\n",
    "    notes = get_notes()\n",
    "    # 准备训练所需序列\n",
    "    network_input, network_output = train_prepare_sequences(notes)\n",
    "    # 构建合适的模型\n",
    "    model = create_network(network_input, notes, True)\n",
    "    # 开始训练\n",
    "    train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show():\n",
    "    # 列出历史记录中的所有数据\n",
    "    print(history.history.keys())\n",
    "    # 总结历史以确保准确性\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # 总结历史损失\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('notes', 'rb') as filepath:\n",
    "    notes = pickle.load(filepath)\n",
    "network_input, network_output = train_prepare_sequences(notes)\n",
    "model = create_network(network_input, notes, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成音乐的准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prepare_sequences(notes):\n",
    "    \"\"\" 准备生成音乐时神经网络所需的序列 \"\"\"\n",
    "    # 获取所有音高名称及个数\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "    # 通过字典来将音高映射为整数\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    sequence_length = 100\n",
    "    network_input = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    n_patterns = len(network_input)\n",
    "    # 将输入调整为与LSTM层兼容的格式\n",
    "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # 将输入标准化\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, notes):\n",
    "    \"\"\" 根据音符序列从神经网络生成音符 \"\"\"\n",
    "    # 获取所有音高名称及个数\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "    # 从输入中选择随机序列作为预测的起点\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "    # 将int整形变量转换为音符\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "    # 产生300个音符\n",
    "    for note_index in range(300):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" 将预测的输出转换为音符，并创建一个Midi音乐文件 \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    # 根据模型生成的值创建音符和和弦对象\n",
    "    for pattern in prediction_output:\n",
    "        # 和弦型\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # 音符型\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        # 每次迭代增加偏移量，保证音符不会堆叠\n",
    "        offset += 0.5\n",
    "    # 将生成的音乐流转换为midi并保存\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='output/test_output5.mid')\n",
    "    midi_stream.write(\"xml\", fp=\"output/test_output5.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \"\"\" 开始生成音乐文件 \"\"\"\n",
    "    # 加载用于训练的音符和弦集合\n",
    "    with open('notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "    # 准备训练神经网络所需的序列\n",
    "    network_input, normalized_input = generate_prepare_sequences(notes)\n",
    "    # 创建用于生成音乐的神经网络\n",
    "    model = create_network(normalized_input, notes, False)\n",
    "    # 生成音符\n",
    "    prediction_output = generate_notes(model, network_input, notes)\n",
    "    # 获取midi音乐文件\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
